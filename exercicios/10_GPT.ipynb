{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH5zeLCt8BUW"
      },
      "source": [
        "# Lista 10 - GPT\n",
        "Nesta lista exploraremos o GPT, um modelo baseado em decoders de Trasformer, usado para a geração de textos. Para todas as questões usaremos o pipeline do huggingface, já utilizado em listas anteriores. Caso necessário consulte a documentação da biblioteca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Z8nHMDMoD9",
        "outputId": "716d3ef4-1346-4149-f7ac-2e0fd445ba7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPUHzstaMqqr"
      },
      "source": [
        "## **Questão 1**\n",
        "\n",
        "Usando a função de pipeline do Hugging Face, carregue o modelo ``gpt2``e use ele para a geração de uma sentença. Forneça o texto inicial que o modelo deve completar e peça para ele fornecer 3 alternativas distintas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFwDPOcbNTph",
        "outputId": "7973d904-9ee7-4495-a56a-cd5d1ea3a0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Hello, welcome to the NLP course, here you are going to learn:\\n\\nWhat you need to know to make this a successful course\\n\\nWhat is a course? What are the different ways you can participate in this?\\n\\nWhat'},\n",
              " {'generated_text': \"Hello, welcome to the NLP course, here you are going to learn everything about nLP and the fundamental rules for programming in R. You'll learn the basics of data structure and data manipulation. For the next section you'll use Data Structures\"},\n",
              " {'generated_text': \"Hello, welcome to the NLP course, here you are going to learn about the very core of NLP including those tools that make the most sense to use on NLP projects. If you've ever had a serious NLP project take the plunge\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "# Insira sua resposta aqui\n",
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)\n",
        "generator(\"Hello, welcome to the NLP course, here you are going to learn\", max_length=50, num_return_sequences=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOiIje2SQJq7"
      },
      "source": [
        "## **Questão 2**\n",
        "\n",
        "Como  os modelos de embeddings, o GPT também é sucetível a aprender vieses negativos presentes nos textos de treinamento. Esses vieses podem aparecer nos textos que ele gera. Gere um texto ou conjunto de textos usando o ``gpt2`` que indique portenciais vieses negativos adquiridos no treinamento. Explicite a seguir que tipo de viés foi detectado."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "generator(\"The professor's name is\", max_length=25, num_return_sequences=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuMP0RR9ATl_",
        "outputId": "05751ead-57bd-4ee9-f76e-e539024ea4d2"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"The professor's name is David King, and you can read about him here.\\n\\nWhen I read that statement, I\"},\n",
              " {'generated_text': \"The professor's name is David T. Tice and he is the author of Overcoming the Panic: The Political Revolution of\"},\n",
              " {'generated_text': \"The professor's name is Paul D. Smith, a law professor at the University of Wisconsin-Madison's College of Law.\"},\n",
              " {'generated_text': \"The professor's name is Matthew Aiken. He's well known in medical, physics and history circles for his controversial analysis of\"},\n",
              " {'generated_text': \"The professor's name is David Z. Haney. He is the chair of the Institute of Advanced Physics at Penn State,\"},\n",
              " {'generated_text': 'The professor\\'s name is \"Charles B. Johnson Jr.\" A spokesman for the school denied there was any controversy about the class'},\n",
              " {'generated_text': \"The professor's name is William W. Ladd of the University of Washington. The book about which little has yet been published\"},\n",
              " {'generated_text': 'The professor\\'s name is now known, but not so that a copy of it will ruin the reputation of the campus. \"'},\n",
              " {'generated_text': 'The professor\\'s name is \"Hangry Christian.\"\\n\\n\"I have a lot of faith in Jesus,\" the professor'},\n",
              " {'generated_text': \"The professor's name is Mark Kuzniak, and he teaches courses on the sociology of crime in a special class called\"},\n",
              " {'generated_text': \"The professor's name is Richard R. Eichner, an American economist who led the New York Fed's study of inflation\"},\n",
              " {'generated_text': 'The professor\\'s name is Richard Wagner, and his work frequently goes under the title \"the great Wagnerian.\" In that sense'},\n",
              " {'generated_text': \"The professor's name is William J. Hirsch and he was an early supporter of Israel, a government supporter, a war\"},\n",
              " {'generated_text': \"The professor's name is Robert D. Stemmer, and he is an academic who has been a professor in mathematics for\"},\n",
              " {'generated_text': \"The professor's name is Peter Z. Smith, professor of economics at the University of Arizona and a former vice president and treasurer\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsWYXb6k8BUo"
      },
      "source": [
        "**Insira sua resposta aqui**\n",
        "\n",
        "Os textos gerados mostram um viés de gênero associando professores universitários com nomes masculinos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMCZlOejRJdU"
      },
      "source": [
        "## **Questão 3**\n",
        "Adicione no pipeline o argumento temperatura. Teste e descreva o seu efeito nos textos gerados quando o parâmetro varia entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4vuTsVhSowk",
        "outputId": "e6bd96fe-b6c9-4069-97ea-4999726db26c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Hello, welcome to the NLP course, here you are going to learn how to write a program that can be used to write a program that can be used to write a program that can be used to write a program that can be used to write'},\n",
              " {'generated_text': 'Hello, welcome to the NLP course, here you are going to learn how to write a program that can be used to write a program that can be used to write a program that can be used to write a program that can be used to write'},\n",
              " {'generated_text': 'Hello, welcome to the NLP course, here you are going to learn how to write a program that can be used to write a program that can be used to write a program that can be used to write a program that can be used to write'}]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "# Insira o código aqui\n",
        "set_seed(42)\n",
        "generator(\"Hello, welcome to the NLP course, here you are going to learn\", max_length=50, num_return_sequences=3, temperature=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "generator(\"Hello, welcome to the NLP course, here you are going to learn\", max_length=50, num_return_sequences=3, temperature=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBU2mfOaWoLo",
        "outputId": "c4c40129-dfeb-4302-bf94-276e9402ee89"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Hello, welcome to the NLP course, here you are going to learn how to use the NLP library.\\n\\nThe first thing you will learn is how to use the NLP library.\\n\\nThe NLP library is a library that'},\n",
              " {'generated_text': 'Hello, welcome to the NLP course, here you are going to learn how to write a program that can be used to create a program that can be used to create a program that can be used to create a program that can be used to create'},\n",
              " {'generated_text': 'Hello, welcome to the NLP course, here you are going to learn about the NLP, how to use it, and how to use it in your own projects.\\n\\nThe NLP is a form of computer science that is based on'}]"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "generator(\"Hello, welcome to the NLP course, here you are going to learn\", max_length=50, num_return_sequences=3, temperature=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXPO4Pm2WvFF",
        "outputId": "12abec1c-94ab-4266-b890-0db1fd02f4bd"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Hello, welcome to the NLP course, here you are going to learn:\\n\\nWhat you need to know to make this a successful course\\n\\nWhat you can learn from the NLP course to make this a success course\\n\\nYou are'},\n",
              " {'generated_text': 'Hello, welcome to the NLP course, here you are going to learn everything about nLP.\\n\\nWhat is NLP?\\n\\nNLP describes the ability to speak and write a logical structure over time.\\n\\nIn this course we'},\n",
              " {'generated_text': \"Hello, welcome to the NLP course, here you are going to learn about the very core of NLP including those important features that make it a better option than a traditional journal. If you've ever had a serious interest in writing about NLP\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wtl4spk8BUr"
      },
      "source": [
        "**Insira sua análise aqui**\n",
        "\n",
        "Analisando os textos gerados é possível ver que quanto maior a temperatura, maior a diferença nas saídas. Quando o parâmetro foi definido com valor 0.01, os resultados foram todos iguais, enquanto a saída para o valores maiores tiveram mais variância.\n",
        "\n",
        "Pelo que consegui entender [1], isso ocorre porque quanto maior o valor, mais suave é a distribuição de probabilidades da saída, assim o modelo tende selecionar palavras diferentes. Quando a temperatura é menor, as palavras com menor probabilidade são penalizadas, e o modelo tende a escolher sempre as mesmas palavras.\n",
        "\n",
        "[1] https://stackoverflow.com/questions/58764619/why-should-we-use-temperature-in-softmax/63471046\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}